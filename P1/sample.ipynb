{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import RidgeCV, Ridge, LassoCV, LassoLars, LassoLarsCV, Lasso, ElasticNet, ElasticNetCV, BayesianRidge\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.constraints import max_norm\n",
    "%matplotlib inline\n",
    "\n",
    "np.random.seed(13)\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training and test sets (assumes you have these in current working directory)\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612863</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.217791</td>\n",
       "      <td>0.233629</td>\n",
       "      <td>0.540962</td>\n",
       "      <td>0.901355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.075030</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.246119</td>\n",
       "      <td>0.143860</td>\n",
       "      <td>0.525384</td>\n",
       "      <td>0.913550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.996325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.436279</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.119091</td>\n",
       "      <td>0.162869</td>\n",
       "      <td>0.361124</td>\n",
       "      <td>0.884824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.997969</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.392743</td>\n",
       "      <td>0.377302</td>\n",
       "      <td>0.613776</td>\n",
       "      <td>0.977236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.998278</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364235</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.096297</td>\n",
       "      <td>0.166459</td>\n",
       "      <td>0.408322</td>\n",
       "      <td>0.921138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Feat 1    Feat 2    Feat 3    Feat 4    Feat 5    Feat 6  Feat 7  \\\n",
       "0   1  0.998952  0.174118  0.999211  0.996460  0.133333  0.057143   0.000   \n",
       "1   2  0.999445  0.174118  0.999329  0.997079  0.133333  0.000000   0.000   \n",
       "2   3  0.998759  0.000000  0.997260  0.996325  0.000000  0.085714   0.125   \n",
       "3   4  0.999619  0.174118  0.997969  0.997321  0.266667  0.057143   0.125   \n",
       "4   5  0.998278  0.174118  0.998427  0.996269  0.200000  0.000000   0.000   \n",
       "\n",
       "   Feat 8  Feat 9  ...  Feat 243  Feat 244  Feat 245  Feat 246  Feat 247  \\\n",
       "0     0.0     0.0  ...       0.0       0.0         0  0.612863  0.026812   \n",
       "1     0.0     0.0  ...       0.0       0.0         0  0.688941  0.075030   \n",
       "2     0.0     0.0  ...       0.0       0.0         0  0.156863  0.436279   \n",
       "3     0.0     0.0  ...       0.0       0.0         0  0.709647  0.075472   \n",
       "4     0.0     0.0  ...       0.0       0.0         0  0.364235  0.041818   \n",
       "\n",
       "   Feat 248  Feat 249  Feat 250  Feat 251    Target  \n",
       "0     0.522  0.217791  0.233629  0.540962  0.901355  \n",
       "1     0.704  0.246119  0.143860  0.525384  0.913550  \n",
       "2     0.000  0.119091  0.162869  0.361124  0.884824  \n",
       "3     0.513  0.392743  0.377302  0.613776  0.977236  \n",
       "4     0.200  0.096297  0.166459  0.408322  0.921138  \n",
       "\n",
       "[5 rows x 253 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 242</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.997841</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728471</td>\n",
       "      <td>0.054397</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.053998</td>\n",
       "      <td>0.667391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497255</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.165514</td>\n",
       "      <td>0.101973</td>\n",
       "      <td>0.506650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.997376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.192069</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.498784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654118</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.451252</td>\n",
       "      <td>0.164180</td>\n",
       "      <td>0.774466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.160433</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Feat 1    Feat 2    Feat 3    Feat 4    Feat 5  Feat 6  Feat 7  \\\n",
       "0   1  0.999849  0.174118  0.999819  0.997841  0.133333     0.2     0.0   \n",
       "1   2  0.999958  0.164706  1.000000  0.996741  0.066667     0.0     0.0   \n",
       "2   3  0.999666  0.174118  0.999479  0.997376  0.000000     0.0     0.0   \n",
       "3   4  0.999735  0.174118  0.999655  0.997173  0.133333     0.0     0.0   \n",
       "4   5  0.999806  0.164706  0.999551  0.997234  0.000000     0.0     0.0   \n",
       "\n",
       "   Feat 8    Feat 9  ...  Feat 242  Feat 243  Feat 244  Feat 245  Feat 246  \\\n",
       "0     0.0  0.000000  ...       0.0       0.0       0.0         0  0.728471   \n",
       "1     0.0  0.000000  ...       0.0       0.0       0.0         0  0.497255   \n",
       "2     0.0  0.000000  ...       0.0       0.0       0.0         0  0.688941   \n",
       "3     0.0  0.363636  ...       0.0       0.0       0.0         0  0.654118   \n",
       "4     0.0  0.000000  ...       0.0       0.0       0.0         0  0.627451   \n",
       "\n",
       "   Feat 247  Feat 248  Feat 249  Feat 250  Feat 251  \n",
       "0  0.054397     0.649  0.416164  0.053998  0.667391  \n",
       "1  0.037736     0.375  0.165514  0.101973  0.506650  \n",
       "2  0.019309     1.000  0.192069  0.120700  0.498784  \n",
       "3  0.019089     0.333  0.451252  0.164180  0.774466  \n",
       "4  0.160433     0.882  0.147407  0.000000  0.481240  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect test set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAEICAYAAABRSj9aAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAGapJREFUeJzt3Xu4XHV97/H3x4SLEG5pcnJCEgho\nfEpoJeoWsdWaIyIYtAGrFCwaEE9E0VNbaAXBGm0p0Soe+mixUTABBcTbkSOxElMQLyBukEsgRSIE\nciPZIQYSVCTJt3+s34bFMHvvmT0ze1Z++byeZ569Zt3mO2tmPuu3fmvNbEUEZmaWrxd0uwAzM+ss\nB72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9DsJSV+Q9NE2resgSVsljUr3b5L0nnasO63ve5Lm\ntGt9TTzuP0naKOnRkX7sdmv3azLS0vvr0AbmmyopJI0eYPo8SV9pf4W7Fgd9BUhaKem3krZI2izp\np5LOlPTM6xMRZ0bEPza4rjcMNk9EPBIRYyJiextqf94HMSLeFBGLWl13k3UcBJwNTI+I/1ln+kxJ\nO1IAbZW0WtK1kl45knWONEmnSfrxINO/IOmKOuOPkPSUpLHDedz0/npwOMta+znoq+MtEbEPcDAw\nH/gwcFm7H2SgllMGDgIei4gNg8yzNiLGAPsARwH/BfxI0tEjUWBFLQLeKmnvmvHvBL4bEZuaWVnG\n76+dW0T41uUbsBJ4Q824I4EdwB+l+wuBf0rD44DvApuBTcCPKHbaV6ZlfgtsBf4emAoEcAbwCHBz\nadzotL6bgIuA24AngO8AY9O0mcDqevUCxwG/B55Oj3dXaX3vScMvAC4AHgY2AFcA+6Vp/XXMSbVt\nBM4fZDvtl5bvS+u7IK3/Dek570h1LKyz7POeRxr/OaC3dP8PgSVpu94PnFSathD4Qpq+BfghcHAT\ny34euD4t+zPgRaXpx1DseB5PNf2wfxum6e8GlgO/Br5f87gBnAk8kN4TnwcEHAb8DtietsvmAbbr\n/cC7SvdHAWuB2aX34i1p3etSfbvXPP5Z6fEfKo17cRo+HvgFxXtrFTCvtGz/e2Buesx1wDml6fOA\nr5TuHwX8NNVyFzCz25/fneHW9QJ8qx/0afwjwPvS8EKeDfqLUuDslm6vBVRvXaUP0hXA3sALqR/0\na4A/SvN8s//DxSBBn4af80Esra8/6N8NrAAOBcYA3wKurKnti6muI4CngMMG2E5XUOyE9knL/hI4\nY6A6a5atOx14PcUOYu90WwWcDowGXkax85leeg22AH8G7AFcAvw4TWtk2ccoQnM08FXgmjRtXFrv\n29Lr+TfAttI2nJ224WFp2QuAn5aeQ1Ds+PenOLLpA45L007rr3GQbXM+8IPS/WPTOnZL919BEbCj\n03ZfDnyo5vGXAGOBF5bGvbi07f+YYqf8UmA9cELNe+DqtA3/OD32895fwKS0DWeldR2T7o/v9me4\n6jd33VTbWooPT62ngYkUrbqnI+JHkT4Jg5gXEU9GxG8HmH5lRCyLiCeBjwIn9Z+sbdFfARdHxIMR\nsRU4Dzi55hD/4xHx24i4i6KVdkTtSlItJwPnRcSWiFgJfIaii6EVaylav/sDbwZWRsSXI2JbRPyC\nYqf39tL810fEzRHxFEVAvlrSlAaX/XZE3BYR2yiCfkYaPwu4NyK+ERFPA/8XKJ9QPhO4KCKWp2X/\nGZgh6eDSPPMjYnNEPALcWFp3I64EXidpcrr/LuCqVAsRcXtE3Jqe10rg34HX1azjoojYVO/9FRE3\nRcQ9EbEjIu6mCPXa5T+e3p/3AF8GTqlT56nA4ohYnNa1BOil2H42CAd9tU2i6Aao9S8ULbwbJD0o\n6dwG1rWqiekPU7QsxzVU5eAOTOsrr3s0MKE0rhxqv6Fo+dcal2qqXdekFuubRNGi3ExxfuRV6YT4\nZkmbKXZU5ZO7z2yntOPaRPEcG1l2oOd5YM16g+e+HgcDl5TWu4li51R+7o1sw7rSzuFm4FRJY4AT\nKI6eAJD0EknflfSopCcodjS1740B31+SXiXpRkl9kh6n2HENtvzDFNuk1sHA22u28WsoGj02CAd9\nRaWrQSYBz7tiIrVoz46IQ4E/B/62dEJxoJb9UC3+KaXhgyiOGjYCTwJ7leoaBYxvYr1rKT6g5XVv\nozh8b8bGVFPtutY0uZ5aJwJ3pCOZVcAPI2L/0m1MRLyvNP8z2ymF4liK59jIsgNZV7Ne8dzXYxXw\n3pp1vzAiftrAuhv9edpFFEdHf0HRz357adqlFOcPpkXEvsBHKHY0jT7OVcB1wJSI2I+i27F2+dr3\n39o661lFceRZ3g57R8T8IZ7bLs9BXzGS9pX0ZuAair7Je+rM82ZJL06B8DjFybYdafJ6iv7wZp0q\nabqkvYBPAN+I4vLLXwJ7Sjpe0m4U/cN7lJZbD0wtXwpa42rgbyQdkoLxn4GvpS6IhqVargUulLRP\n6rb4W6Dpa6xVmCTpY8B7KIILin7ul0h6p6Td0u2Vkg4rLT5L0msk7Q78I3BrRKxqcNmBXA8cLumt\nqUvr//DcI4EvAOdJOjzVv5+kt9dZTz3rgcmp3sF8kyJgP04R+mX7UJxI3SrpD4FGdl61y2+KiN9J\nOhJ4R515Pippr/QcTwe+VmeerwBvkXSspFGS9kyXzU6uM6+VOOir4/9L2kLRajkfuJjiDV/PNOAH\nFFdS3AL8W0TcmKZdBFyQDm3PaeLxr6Q4YfgosCdF2BARjwPvB75E0Xp+ElhdWu7r6e9jku6os97L\n07pvBh6iuArkg03UVfbB9PgPUhzpXJXW36gDJW2l2G4/pzjxNzMiboDiSAl4I8W5gLUU2+KTPHfH\ndhXwMYruk1dQ9Bs3umxdEbGRoi9/PsXJxWnAT0rTv53WdU3qOlkGvKnB5/yfwL3Ao5I2DlLDkxRh\nP5ni/EHZORThvIXixHm9EB7M+4FPpPf3P1DssGv9kKI7cinw6f7XpKbGVRQnpj9CccJ2FfB3OMeG\n1H+lhpkNQdJCiit3Luh2LWbN8J7QzCxzDnozs8y568bMLHNu0ZuZZa4SP0A0bty4mDp1arfLMDPb\nqdx+++0bI2L8UPNVIuinTp1Kb29vt8swM9upSHp46LncdWNmlj0HvZlZ5hz0ZmaZc9CbmWXOQW9m\nljkHvZlZ5hz0ZmaZc9CbmWXOQW9mlrlKfDPWrBlTz73+meGV84/vYiVmOwe36M3MMuegNzPLnIPe\nzCxzDnozs8z5ZKztFMonYAca7xOzZvW5RW9mlrkhg17SFEk3SrpP0r2S/jqNnydpjaQ7021WaZnz\nJK2QdL+kYzv5BMzMbHCNdN1sA86OiDsk7QPcLmlJmvbZiPh0eWZJ04GTgcOBA4EfSHpJRGxvZ+Fm\nZtaYIVv0EbEuIu5Iw1uA5cCkQRaZDVwTEU9FxEPACuDIdhRrZmbNa6qPXtJU4GXAz9KoD0i6W9Ll\nkg5I4yYBq0qLrabOjkHSXEm9knr7+vqaLtzMzBrTcNBLGgN8E/hQRDwBXAq8CJgBrAM+08wDR8SC\niOiJiJ7x44f8J+ZmZjZMDQW9pN0oQv6rEfEtgIhYHxHbI2IH8EWe7Z5ZA0wpLT45jTMzsy5o5Kob\nAZcByyPi4tL4iaXZTgSWpeHrgJMl7SHpEGAacFv7SjYzs2Y0ctXNnwLvBO6RdGca9xHgFEkzgABW\nAu8FiIh7JV0L3Edxxc5ZvuLGzKx7hgz6iPgxoDqTFg+yzIXAhS3UZWZmbeJvxpqZZc5Bb2aWOQe9\nmVnmHPRmZplz0JuZZc6/R2/Z8G/Tm9XnFr2ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeYc9GZmmXPQ\nm5llztfRW2WVr4s3s+Fzi97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8uc\ng97MLHMOejOzzDnozcwy56A3M8ucg97MLHMOejOzzDnozcwy56A3M8vckP94RNIU4ApgAhDAgoi4\nRNJY4GvAVGAlcFJE/FqSgEuAWcBvgNMi4o7OlG9WX/mflqycf3wXKzHrvkZa9NuAsyNiOnAUcJak\n6cC5wNKImAYsTfcB3gRMS7e5wKVtr9rMzBo2ZNBHxLr+FnlEbAGWA5OA2cCiNNsi4IQ0PBu4Igq3\nAvtLmtj2ys3MrCFN9dFLmgq8DPgZMCEi1qVJj1J07UCxE1hVWmx1Gle7rrmSeiX19vX1NVm2mZk1\nquGglzQG+CbwoYh4ojwtIoKi/75hEbEgInoiomf8+PHNLGpmZk0Y8mQsgKTdKEL+qxHxrTR6vaSJ\nEbEudc1sSOPXAFNKi09O48y6widmbVc3ZIs+XUVzGbA8Ii4uTboOmJOG5wDfKY1/lwpHAY+XunjM\nzGyENdKi/1PgncA9ku5M4z4CzAeulXQG8DBwUpq2mOLSyhUUl1ee3taKzcysKUMGfUT8GNAAk4+u\nM38AZ7VYl5mZtYm/GWtmljkHvZlZ5hz0ZmaZc9CbmWXOQW9mlrmGvjBl1kn+QpNZZ7lFb2aWOQe9\nmVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnm/BMIVinln0Mws/Zw\ni97MLHNu0dsuxT+gZrsit+jNzDLnoDczy5yD3swscw56M7PM+WSsdYUvozQbOW7Rm5llzkFvZpY5\nB72ZWeYc9GZmmXPQm5llzkFvZpY5B72ZWeaGDHpJl0vaIGlZadw8SWsk3Zlus0rTzpO0QtL9ko7t\nVOFmZtaYRlr0C4Hj6oz/bETMSLfFAJKmAycDh6dl/k3SqHYVa2ZmzRsy6CPiZmBTg+ubDVwTEU9F\nxEPACuDIFuozM7MWtdJH/wFJd6eunQPSuEnAqtI8q9O455E0V1KvpN6+vr4WyjAzs8EMN+gvBV4E\nzADWAZ9pdgURsSAieiKiZ/z48cMsw8zMhjKsoI+I9RGxPSJ2AF/k2e6ZNcCU0qyT0zgzM+uSYf16\npaSJEbEu3T0R6L8i5zrgKkkXAwcC04DbWq7SbAT43wxaroYMeklXAzOBcZJWAx8DZkqaAQSwEngv\nQETcK+la4D5gG3BWRGzvTOlmZtaIIYM+Ik6pM/qyQea/ELiwlaLMzKx9/M1YM7PMOejNzDLnoDcz\ny5z/Z6ztsvx/a21X4Ra9mVnmHPRmZplz0JuZZc5Bb2aWOQe9mVnmHPRmZplz0JuZZc7X0duI8XXr\nZt3hFr2ZWeYc9GZmmXPXjbWd/4GHWbW4RW9mljkHvZlZ5hz0ZmaZcx+92RB8zsF2dm7Rm5llzkFv\nZpY5B72ZWeYc9GZmmfPJWDOzETbSJ/gd9NZR/iEzs+5z142ZWeYc9GZmmXPQm5llzn30ZnX43ILl\nxC16M7PMDRn0ki6XtEHSstK4sZKWSHog/T0gjZekf5W0QtLdkl7eyeLNzGxojbToFwLH1Yw7F1ga\nEdOApek+wJuAaek2F7i0PWWamdlwDRn0EXEzsKlm9GxgURpeBJxQGn9FFG4F9pc0sV3FmplZ84bb\nRz8hItal4UeBCWl4ErCqNN/qNO55JM2V1Cupt6+vb5hlmJnZUFo+GRsRAcQwllsQET0R0TN+/PhW\nyzAzswEMN+jX93fJpL8b0vg1wJTSfJPTODMz65LhBv11wJw0PAf4Tmn8u9LVN0cBj5e6eMzMrAuG\n/MKUpKuBmcA4SauBjwHzgWslnQE8DJyUZl8MzAJWAL8BTu9AzWZm1oQhgz4iThlg0tF15g3grFaL\nMjOz9vE3Y83MMuegNzPLnIPezCxzDnozs8w56M3MMuegNzPLnIPezCxzDnozs8z5XwlaW+wq/3qv\n/DxXzj++i5WYNc5Bb8O2q4S72c7OQW/WBm7pW5W5j97MLHNu0Zt1kFv6VgVu0ZuZZc5Bb2aWOQe9\nmVnmHPRmZplz0JuZZc5Bb2aWOV9eadZm/sawVY1b9GZmmXPQm5llzl031hR3SwyfvyVr3eIWvZlZ\n5hz0ZmaZc9eN2TC5G8t2Fm7Rm5llzkFvZpY5B72ZWebcR29Dcl+02c6tpaCXtBLYAmwHtkVEj6Sx\nwNeAqcBK4KSI+HVrZdpI8HXeZnlqR9fN/4qIGRHRk+6fCyyNiGnA0nTfzMy6pBN99LOBRWl4EXBC\nBx7DzMwa1GrQB3CDpNslzU3jJkTEujT8KDCh3oKS5krqldTb19fXYhlmZjaQVk/GviYi1kj6H8AS\nSf9VnhgRISnqLRgRC4AFAD09PXXnMTOz1rUU9BGxJv3dIOnbwJHAekkTI2KdpInAhjbUaSPMV9qY\n5WPYXTeS9pa0T/8w8EZgGXAdMCfNNgf4TqtFmpnZ8LXSop8AfFtS/3quioj/kPRz4FpJZwAPAye1\nXqaZmQ3XsIM+Ih4Ejqgz/jHg6FaKspHjLhqz/PmbsWZd5i+qWaf5t27MzDLnFr2ZWQNquzl3pqMv\nB71ZF/jciI0kd92YmWXOLfpdwM58yGkFn7CtnoGOyqr4+jjozTLkHYOVOejNKsQBbZ3gPnozs8y5\nRb8L8hUfO4dGXicfAVgjHPQZ8YfezOpx0JuZjYBuHkk76M0y4S45G4hPxpqZZc5Bb2aWOXfdZMqH\n8fnyazt8u+oFCw56s8y1M9x2taDMZafqoN/J5fJGtJG3q4X2rsx99GZmmXOL3sysjap4pOSgN7Pn\nGM7PWnc63BpZfys1dKoLtCpdqw76iqlia8DyUZXgKev077pX8TmPNAe9mQ1qoKB0gO48HPRmll1o\n5/Z8WuWgrwD/HK3lZKD3arPvYYd1+zjozaxjHNbV4KA3sxHXyg7AR7fNU0R0uwZ6enqit7e322V0\nXCOHtGa2a2llZyXp9ojoGWo+fzPWzCxz7rrpErfizWykOOjbxN0yZlZVHQt6SccBlwCjgC9FxPxO\nPVYntHKJmMPdzKqkI0EvaRTweeAYYDXwc0nXRcR97X6skTgD728GmtnOrFMt+iOBFRHxIICka4DZ\nQNuDfjBufZuZdS7oJwGrSvdXA68qzyBpLjA33d0q6f6adYwDNjbzoPrk8KYNQ9O1jbAq1+fahq/K\n9bm2YdInW6rv4EZm6trJ2IhYACwYaLqk3kauD+2GKtcG1a7PtQ1fletzbcM3EvV16jr6NcCU0v3J\naZyZmY2wTgX9z4Fpkg6RtDtwMnBdhx7LzMwG0ZGum4jYJukDwPcpLq+8PCLubXI1A3brVECVa4Nq\n1+fahq/K9bm24et4fZX4rRszM+sc/9aNmVnmHPRmZpnrStBLOk7S/ZJWSDq3zvSDJN0o6ReS7pY0\nq870rZLOqVJtkl4q6RZJ90q6R9KeVahN0m6SFqWalks6r511NVHfwZKWptpukjS5NG2OpAfSbU5V\napM0o/Sa3i3pL6tSW2n6vpJWS/pcu2trtb70nrwhve/ukzS1QrV9Kr2uyyX9qyS1ubbLJW2QtGyA\n6UqPuyLV9/LStPZ+HiJiRG8UJ2d/BRwK7A7cBUyvmWcB8L40PB1YWTP9G8DXgXOqUhvFie27gSPS\n/T8ARlWktncA16ThvYCVwNQubLuvA3PS8OuBK9PwWODB9PeANHxARWp7CTAtDR8IrAP2r0JtpemX\nAFcBn2vna9qO+oCbgGPS8BhgryrUBvwJ8JO0jlHALcDMNm+7PwNeDiwbYPos4HuAgKOAn3Xq89CN\nFv0zP48QEb8H+n8eoSyAfdPwfsDa/gmSTgAeApq9iqfTtb0RuDsi7gKIiMciYntFagtgb0mjgRcC\nvweeaGNtjdY3HfjPNHxjafqxwJKI2BQRvwaWAMdVobaI+GVEPJCG1wIbgPFVqA1A0iuACcANbayp\nLfVJmg6MjoglABGxNSJ+U4XaKD4Te1LsIPYAdgPWt7E2IuJmYNMgs8wGrojCrcD+kibSgc9DN4K+\n3s8jTKqZZx5wqqTVwGLggwCSxgAfBj5etdooWn4h6fuS7pD09xWq7RvAkxSt0UeAT0fEYG/ATtV3\nF/DWNHwisI+kP2hw2W7V9gxJR1IEw6+qUJukFwCfAdrehdmO+ig+E5slfSt1J/6Lih887HptEXEL\nRfCvS7fvR8TyNtbWiIHqb/vnoaonY08BFkbEZIrDmyvTm3oe8NmI2FrB2kYDrwH+Kv09UdLRFant\nSGA7RdfDIcDZkg4d4dqgCKTXSfoF8DqKb0u386inFYPWllpaVwKnR8SOitT2fmBxRKwe4XpqDVTf\naOC1aforKbpYTqtCbZJeDBxG8a39ScDrJb12hGsbMd34rZtGfh7hDNKhSkTcouKk5jiKH0Z7m6RP\nAfsDOyT9LiLadRKqldpWAzdHxEYASYsp+ueWVqC2dwD/ERFPAxsk/QTooej7a5ch60tdH2+FZ47O\n/iIiNktaA8ysWfamKtSW7u8LXA+cnw6x26mV7fZq4LWS3k/R/727pK0R8byTkl2qbzVwZzz7K7b/\nj6Iv+rIK1Pa/gVv7G42Svge8GvhRm2prxED1t//z0M6TDw2eoBhNETCH8OwJlMNr5vkecFoaPoyi\nr1k188yj/Sdjh10bxUmTOyhOdo4GfgAcX5HaPgx8OY3fm+Lnol/ahW03DnhBGr4Q+EQ8e/LpobQN\nD0jDYytS2+4UO+sPdfHzULe2mnlOozMnY1vZdqPS/OPT/S8DZ1Wktr9Mn9HRFP3zS4G3dGD7TWXg\nk7HH89yTsbd16vPQ9jdug09+FvBLir7O89O4TwB/noanU5wRvwu4E3hjnXXMo81B32ptwKkUJ4mX\nAZ+qSm0Urb2vp9ruA/6uS6/r24AH0jxfAvYoLftuYEW6nV6V2tJr+nTanv23GVWorWYdp9GBoG/D\n63oMxdVo9wALgd2rUBvFTujfgeXpM3FxB7bb1RT9/09THPGfAZwJnJmmi+IfNP0qbZ+eTn0e/BMI\nZmaZq+rJWDMzaxMHvZlZ5hz0ZmaZc9CbmWXOQW9mljkHvZlZ5hz0ZmaZ+28RzwfnF0u2wwAAAABJ\nRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore distribution of target\n",
    "plt.hist(train['Target'], bins = 100)\n",
    "plt.title(\"Distribution of Dependent Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split training set into X and y (removing first column containing IDs)\n",
    "X_train = train.iloc[:, 1:-1]\n",
    "y_train = train.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define function to compute RMSE\n",
    "def scoreRMSE(predictor, X, true_y):\n",
    "    predictions = predictor.predict(X)\n",
    "    return np.sqrt(mean_squared_error(predictions, true_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.02635316898374967\n"
     ]
    }
   ],
   "source": [
    "# Fit unregularized linear regression and see RMSE on training set\n",
    "linReg = Lin_Reg()\n",
    "linReg.fit(X_train, y_train)\n",
    "\n",
    "print \"Training RMSE: \", scoreRMSE(linReg, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# attempt at Bayesian\n",
    "# reg = BayesianRidge().fit(X_train, y_train)\n",
    "# score = scoreRMSE(reg, X_train, y_train)\n",
    "# print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# https://machinelearningmastery.com/tutorial-first-neural-network-python-keras/\n",
    "# https://stats.stackexchange.com/questions/350718/confused-in-selecting-the-number-of-hidden-layers-and-neurons-in-an-mlp-for-a-bi\n",
    "# attempt at neural network\n",
    "from keras.constraints import maxnorm\n",
    "from keras import regularizers\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras.layers import Activation, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# compile model\n",
    "# model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def run_models(seeds):\n",
    "    predictions_all = [[] for x in xrange(len(seeds))]\n",
    "    for s in range(len(seeds)):\n",
    "        np.random.seed(seeds[s])\n",
    "        model = Sequential()\n",
    "        model.add(Dense(376, input_dim=251, kernel_initializer = 'normal', activation = 'relu'))\n",
    "        model.add(Dense(128, kernel_initializer = 'normal', activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(64, kernel_initializer = 'normal', activation = 'relu'))\n",
    "        model.add(Dropout(0.3))\n",
    "        model.add(Dense(16, kernel_initializer = 'normal', activation = 'relu'))\n",
    "        model.add(Dropout(0.2))\n",
    "        model.add(Dense(1, kernel_initializer = 'normal', activation='sigmoid'))\n",
    "        \n",
    "        model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "        \n",
    "        # https://datascience.stackexchange.com/questions/18414/are-there-any-rules-for-choosing-the-size-of-a-mini-batch\n",
    "        history = model.fit(X_train, y_train, validation_split=0.2, epochs=50, batch_size=64,  verbose=2)\n",
    "        \n",
    "        # https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
    "        plt.clf()\n",
    "        plt.plot(np.log(history.history['loss']))\n",
    "        plt.plot(np.log(history.history['val_loss']))\n",
    "        plt.title('model loss with seed' + str(seeds[s]))\n",
    "        plt.ylabel('log(loss)')\n",
    "        plt.xlabel('epoch')\n",
    "        plt.legend(['train', 'test'], loc='upper left')\n",
    "        plt.show()\n",
    "        predictions = model.predict(X_test)\n",
    "        predictions_all[s] = predictions\n",
    "    return predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# predict NN\n",
    "predictions_all = run_models([23, 37, 97])\n",
    "predictions = np.mean(predictions_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def adjust_final_distribution():\n",
    "    # mean and sd\n",
    "    train_mean = np.mean(train['Target'])\n",
    "    train_std = np.std(train['Target'])\n",
    "    # train_mean = np.mean(train.loc[train['Target'] < 0.98]['Target'])\n",
    "    # train_std = np.std(train.loc[train['Target'] < 0.98]['Target'])\n",
    "    print(train_mean, train_std)\n",
    "\n",
    "    # readjust distribution\n",
    "    y_predictions = model.predict(X_train)\n",
    "    plt.clf()\n",
    "    plt.hist(y_predictions, bins = 100)\n",
    "    plt.show()\n",
    "\n",
    "    # https://stats.stackexchange.com/questions/46429/transform-data-to-desired-mean-and-standard-deviation\n",
    "    test_mean = np.mean(y_predictions)\n",
    "    test_std = np.std(y_predictions)\n",
    "    print(test_mean, test_std)\n",
    "\n",
    "    y_predictions_adj = test_mean + (y_predictions -  train_mean) * test_std / train_std\n",
    "    plt.clf()\n",
    "    plt.hist(y_predictions_adj, bins = 100)\n",
    "    plt.show()\n",
    "    \n",
    "    # plot predicted model, predicted model with adjustment, truth\n",
    "    plt.clf()\n",
    "    ax1 = plt.subplot(131)\n",
    "    ax1.plot(range(0, len(X_train)), y_train, label = \"truth\")\n",
    "    ax1.set_ylim([0,1.5])\n",
    "\n",
    "    ax2 = plt.subplot(132)\n",
    "    ax2.plot(range(0, len(X_train)), y_predictions, label = \"model\")\n",
    "    ax2.set_ylim(0,1.5)\n",
    "\n",
    "    ax3 = plt.subplot(133)\n",
    "    ax3.plot(range(0, len(X_train)), y_predictions_adj, label = \"adjusted\")\n",
    "    ax3.set_ylim(0,1.5)\n",
    "    \n",
    "    # adjusted error\n",
    "    no_adj_loss = np.sqrt(mean_squared_error(y_predictions, y_train))\n",
    "    adj_loss = np.sqrt(mean_squared_error(y_predictions_adj, y_train))\n",
    "    print(no_adj_loss)\n",
    "    print(adj_loss)\n",
    "\n",
    "    # evaluate model\n",
    "    loss = scoreRMSE(model, X_train, y_train)\n",
    "    loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# plot optimal alpha vs. loss for functions\n",
    "def cross_validation(functions_opt, functions, alphas_vals, labels):\n",
    "    scores = []\n",
    "    alphas_opt = []\n",
    "    \n",
    "    predictions_all = [[] for x in xrange(len(functions))]\n",
    "    \n",
    "    for index in range(len(functions)):\n",
    "        reg = functions_opt[index](alphas = alphas_vals, cv=10).fit(X_train, y_train)\n",
    "        alphas_opt.append(reg.alpha_)\n",
    "        print(reg.alpha_)\n",
    "        reg_opt = functions[index](alpha=reg.alpha_).fit(X_train, y_train)\n",
    "        predict = reg_opt.predict(X_test)\n",
    "        predictions_all[index] = predict\n",
    "#         score = scoreRMSE(reg_opt, X_train, y_train)\n",
    "#         scores.append(score)\n",
    "    \n",
    "#     index = np.arange(len(labels))\n",
    "#     plt.clf()\n",
    "#     plt.bar(index, scores)\n",
    "#     plt.xlabel('model', fontsize=5)\n",
    "#     plt.ylabel('scoreRMSE', fontsize=5)\n",
    "#     plt.xticks(index, labels, fontsize=5, rotation=30)\n",
    "#     plt.show()\n",
    "    \n",
    "    return predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictions_all = cross_validation([LassoCV], [Lasso], np.linspace(0.01,50,200), ['lasso'])\n",
    "predictions = np.mean(predictions_all, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# trying cross_validation\n",
    "# reg = LassoCV(cv=10, random_state=0).fit(X_train, y_train)\n",
    "# reg = LassoLarsCV(cv=10).fit(X_train, y_train)\n",
    "reg = ElasticNetCV(cv=10, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_performance(functions, alpha_vals, labels):\n",
    "    scores =[[] for x in xrange(len(functions))]\n",
    "    predictions_all = [[] for x in xrange(len(functions))]\n",
    "    \n",
    "    for alpha_val in alpha_vals:\n",
    "        for index in range(len(functions)):\n",
    "            reg = functions[index](alpha=alpha_val).fit(X_train, y_train)\n",
    "            predict = reg_opt.predict(X_test)\n",
    "            predictions_all[index] = predict\n",
    "            score = scoreRMSE(reg, X_train, y_train)\n",
    "            scores[index].append(score)\n",
    "            \n",
    "    plt.clf()\n",
    "    for loss in scores:\n",
    "        plt.plot(alpha_vals, loss)\n",
    "    plt.legend(labels, loc='bottom left')\n",
    "    plt.show()\n",
    "    return predictions_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_performance([Ridge, Lasso, ElasticNet], np.linspace(0.01,100,200), ['ridge', 'lasso', 'elasticnet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>Feat 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 242</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.997841</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728471</td>\n",
       "      <td>0.054397</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.053998</td>\n",
       "      <td>0.667391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497255</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.165514</td>\n",
       "      <td>0.101973</td>\n",
       "      <td>0.506650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.997376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.192069</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.498784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654118</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.451252</td>\n",
       "      <td>0.164180</td>\n",
       "      <td>0.774466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.160433</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feat 1    Feat 2    Feat 3    Feat 4    Feat 5  Feat 6  Feat 7  Feat 8  \\\n",
       "0  0.999849  0.174118  0.999819  0.997841  0.133333     0.2     0.0     0.0   \n",
       "1  0.999958  0.164706  1.000000  0.996741  0.066667     0.0     0.0     0.0   \n",
       "2  0.999666  0.174118  0.999479  0.997376  0.000000     0.0     0.0     0.0   \n",
       "3  0.999735  0.174118  0.999655  0.997173  0.133333     0.0     0.0     0.0   \n",
       "4  0.999806  0.164706  0.999551  0.997234  0.000000     0.0     0.0     0.0   \n",
       "\n",
       "     Feat 9   Feat 10  ...  Feat 242  Feat 243  Feat 244  Feat 245  Feat 246  \\\n",
       "0  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.728471   \n",
       "1  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.497255   \n",
       "2  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.688941   \n",
       "3  0.363636  0.166667  ...       0.0       0.0       0.0         0  0.654118   \n",
       "4  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.627451   \n",
       "\n",
       "   Feat 247  Feat 248  Feat 249  Feat 250  Feat 251  \n",
       "0  0.054397     0.649  0.416164  0.053998  0.667391  \n",
       "1  0.037736     0.375  0.165514  0.101973  0.506650  \n",
       "2  0.019309     1.000  0.192069  0.120700  0.498784  \n",
       "3  0.019089     0.333  0.451252  0.164180  0.774466  \n",
       "4  0.160433     0.882  0.147407  0.000000  0.481240  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove first column to make predictions\n",
    "X_test = test.iloc[:, 1:]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make predictions with our model\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions using linear regression model fitted above\n",
    "# predictions = linReg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.935183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.913122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.916378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.927222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.934416</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id  Predicted\n",
       "0  1   0.935183\n",
       "1  2   0.913122\n",
       "2  3   0.916378\n",
       "3  4   0.927222\n",
       "4  5   0.934416"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format predictions to be compatible with Kaggle upload\n",
    "sample_submission = pd.DataFrame(data=predictions, columns=['Predicted'])\n",
    "sample_submission.insert(0, \"Id\", range(1, 1 + X_test.shape[0]))\n",
    "sample_submission['Id'] = sample_submission['Id'].astype(str)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save predictions to .csv file for upload to Kaggle\n",
    "sample_submission.to_csv(\"Single_feature_LGBM_Random_Search_Log2_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/christinejou/anaconda/lib/python2.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet, Lasso\n",
    "from sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.base import BaseEstimator, TransformerMixin, RegressorMixin, clone\n",
    "from sklearn.model_selection import KFold, cross_val_score, train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "n_folds = 10\n",
    "\n",
    "def rmsle_cv(model):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=97).get_n_splits(X_train)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X_train, y_train, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lasso = make_pipeline(RobustScaler(), Lasso(alpha =0.0005, random_state=1))\n",
    "ENet = make_pipeline(RobustScaler(), ElasticNet(alpha=0.0005, l1_ratio=.9, random_state=3))\n",
    "KRR = KernelRidge(alpha=0.6, kernel='polynomial', degree=2, coef0=2.5)\n",
    "GBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.05,\n",
    "                                   max_depth=4, max_features='sqrt',\n",
    "                                   min_samples_leaf=15, min_samples_split=10, \n",
    "                                   loss='huber', random_state =5)\n",
    "model_xgb = xgb.XGBRegressor(colsample_bytree=0.4603, gamma=0.0468, \n",
    "                             learning_rate=0.05, max_depth=3, \n",
    "                             min_child_weight=1.7817, n_estimators=2200,\n",
    "                             reg_alpha=0.4640, reg_lambda=0.8571,\n",
    "                             subsample=0.5213, silent=1,\n",
    "                             random_state =7, nthread = -1)\n",
    "model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=5,\n",
    "                              learning_rate=0.01, n_estimators=720,\n",
    "                              max_bin = 30, bagging_fraction = 0.8,\n",
    "                              bagging_freq = 5, feature_fraction = 0.65,\n",
    "                              feature_fraction_seed=9, bagging_seed=9,\n",
    "                              min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso score: 0.0274 (0.0012)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(lasso)\n",
    "print(\"\\nLasso score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(ENet)\n",
    "print(\"ElasticNet score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(KRR)\n",
    "print(\"Kernel Ridge score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "score = rmsle_cv(model_xgb)\n",
    "print(\"XGBoost score: {:.4f} ({:.4f})\\n\".format(score.mean(), score.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lightgbm score: ', 0.026927759992079643, '(', 0.0012218959301145062, ')')\n"
     ]
    }
   ],
   "source": [
    "score = rmsle_cv(model_lgb)\n",
    "print(\"lightgbm score: \", score.mean(), \"(\", score.std(), \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model_lgb.fit(X_train, y_train)\n",
    "lgb_train_pred = model_lgb.predict(X_train)\n",
    "predictions = lgb_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lasso.fit(X_train, y_train)\n",
    "lasso_pred = lasso.predict(X_test)\n",
    "predictions = lasso_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "KRR.fit(X_train, y_train)\n",
    "KRR_pred = KRR.predict(X_test)\n",
    "predictions = KRR_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(lgb_train_pred, bins = 100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.sqrt(mean_squared_error(lgb_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_single_feature(X_train, X_test):\n",
    "    cols = X_train.columns\n",
    "    single_val = []\n",
    "    for index in cols:\n",
    "        if (len(X_train[index].unique()) == 1):\n",
    "            single_val.append(index)\n",
    "\n",
    "    test_val = []\n",
    "    for index in single_val:\n",
    "        if (len(X_test[index].unique()) == 1):\n",
    "            test_val.append(index)\n",
    "            \n",
    "    single_feature = list(set(single_val).intersection(set(test_val)))\n",
    "    \n",
    "    X_single_train = X_train.drop(columns=single_feature)\n",
    "    X_single_test = X_test.drop(columns=single_feature)\n",
    "\n",
    "    return X_single_train, X_single_test, single_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_single_train, X_single_test, single_feature = remove_single_feature(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Cross-Validation\n",
    "n_folds = 10\n",
    "\n",
    "def rmsle_cv_single(model, X, Y):\n",
    "    kf = KFold(n_folds, shuffle=True, random_state=97).get_n_splits(X)\n",
    "    rmse= np.sqrt(-cross_val_score(model, X, Y, scoring=\"neg_mean_squared_error\", cv = kf))\n",
    "    return(rmse)\n",
    "\n",
    "def train_lgb(X_train, X_test, y):\n",
    "    model_lgb = lgb.LGBMRegressor(objective='regression',num_leaves=51,\n",
    "                                  learning_rate = 0.01, n_estimators=300,\n",
    "                                  max_bin = 30, bagging_fraction = 0.65,\n",
    "                                  bagging_freq = 5, feature_fraction = 0.65,\n",
    "                                  feature_fraction_seed=13, bagging_seed=13,\n",
    "                                  min_data_in_leaf =6, min_sum_hessian_in_leaf = 11)\n",
    "    score = rmsle_cv_single(model_lgb, X_train, y_train)\n",
    "    print(\"lightgbm score: \", score.mean(), \"(\", score.std(), \")\")\n",
    "    model_lgb.fit(X_train, y_train)\n",
    "    lgb_train_pred = model_lgb.predict(X_test)\n",
    "    return lgb_train_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# np.sqrt(mean_squared_error(lgb_train_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def scale_and_pca(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train.values)\n",
    "    X_train_scale = scaler.transform(X_train.values)\n",
    "    X_test_scale = scaler.transform(X_test.values)\n",
    "    \n",
    "    pca = PCA(0.99)\n",
    "    \n",
    "    pca.fit(X_train_scale)\n",
    "    \n",
    "    X_train_scale_pca = pca.transform(X_train_scale)\n",
    "    X_test_scale_pca = pca.transform(X_test_scale)\n",
    "    \n",
    "    return X_train_scale_pca, X_test_scale_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train_scale_pca, X_test_scale_pca = scale_and_pca(X_single_train, X_single_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_linear_loss(X):\n",
    "    linReg = Lin_Reg()\n",
    "    linReg.fit(X, y_train)\n",
    "\n",
    "    print \"Training RMSE: \", scoreRMSE(linReg, X, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.02682121907766576\n"
     ]
    }
   ],
   "source": [
    "get_linear_loss(X_train_scale_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0263531688357\n"
     ]
    }
   ],
   "source": [
    "get_linear_loss(X_single_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.0263531688357\n"
     ]
    }
   ],
   "source": [
    "get_linear_loss(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def remove_high_correlation(X_train, X_test):\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    high_corr_var=np.where(corr_matrix>0.999)\n",
    "    high_corr_var=[(corr_matrix.columns[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "    \n",
    "    remove_vars = [i[0] for i in high_corr_var]\n",
    "    print(remove_vars)\n",
    "    \n",
    "    X_corr_train = X_train.drop(columns=remove_vars)\n",
    "    X_corr_test = X_test.drop(columns=remove_vars)\n",
    "    return X_corr_train, X_corr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Feat 19', 'Feat 96']\n"
     ]
    }
   ],
   "source": [
    "new_X, new_test = remove_high_correlation(X_single_train, X_single_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train1_rsa, test1_rsa = scale_and_pca(X_single_train, X_single_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.02682121907766576\n"
     ]
    }
   ],
   "source": [
    "get_linear_loss(train1_rsa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lightgbm score: ', 0.027233035282325423, '(', 0.0011826687850171951, ')')\n"
     ]
    }
   ],
   "source": [
    "predictions = train_lgb(train1_rsa, test1_rsa, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###\n",
    "epsilon_X_train = X_single_train.replace(0, 10 ** (-100))\n",
    "epsilon_X_test = X_single_test.replace(0, 10 ** (-100))\n",
    "log_e_X_train = np.log(epsilon_X_train)\n",
    "log_e_X_test = np.log(epsilon_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.02649037403657469\n"
     ]
    }
   ],
   "source": [
    "get_linear_loss(log_e_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lightgbm score: ', 0.026656433029968646, '(', 0.0012339408403312694, ')')\n"
     ]
    }
   ],
   "source": [
    "# original 5 leaves, 720\n",
    "predictions = train_lgb(X_single_train, X_single_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# stds = list(X_train.std(axis = 1))\n",
    "# [i for i in stds if i >= 0.2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lightgbm score: ', 0.02658367299748282, '(', 0.0012370012597613866, ')')\n"
     ]
    }
   ],
   "source": [
    "# original 63 leaves, 720\n",
    "predictions = train_lgb(X_single_train, X_single_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lightgbm score: ', 0.0266531898208971, '(', 0.0012361313943701439, ')')\n"
     ]
    }
   ],
   "source": [
    "# random search\n",
    "predictions = train_lgb(X_single_train, X_single_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "          estimator=LGBMRegressor(bagging_freq=5, bagging_seed=13, boosting_type='gbdt',\n",
       "       class_weight=None, colsample_bytree=1.0, feature_fraction_seed=13,\n",
       "       importance_type='split', learning_rate=0.01, max_bin=30,\n",
       "       max_depth=8, min_child_samples=20, min_child_weight=0.001,\n",
       "       min_data_i...=0.0, reg_lambda=0.0, silent=True,\n",
       "       subsample=1.0, subsample_for_bin=200000, subsample_freq=0),\n",
       "          fit_params=None, iid='warn', n_iter=20, n_jobs=None,\n",
       "          param_distributions={'n_estimators': [100, 200, 300], 'num_leaves': [31, 36, 41, 46, 51, 56, 61, 63], 'bagging_fraction': [0.65, 0.7, 0.75, 0.8, 0.85, 0.9], 'feature_fraction': [0.65, 0.7, 0.75, 0.8, 0.85, 0.9]},\n",
       "          pre_dispatch='2*n_jobs', random_state=None, refit=True,\n",
       "          return_train_score='warn', scoring=None, verbose=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf = lgb.LGBMRegressor(objective='regression',\n",
    "                                  learning_rate = 0.01,\n",
    "                                  max_bin = 30, bagging_freq = 5,\n",
    "                                  feature_fraction_seed=13, bagging_seed=13,\n",
    "                                  min_data_in_leaf =6, min_sum_hessian_in_leaf = 11, max_depth = 8)\n",
    "\n",
    "# use a full grid over all parameters\n",
    "param_dist = {\"num_leaves\": [31,36,41,46,51,56,61,63],\n",
    "              \"feature_fraction\": [0.65, 0.7, 0.75, 0.8, 0.85, 0.9],\n",
    "              \"n_estimators\": [100, 200, 300],\n",
    "              \"bagging_fraction\": [0.65, 0.7, 0.75, 0.8, 0.85, 0.9]\n",
    "             }\n",
    "\n",
    "n_iter_search = 20\n",
    "random_search = RandomizedSearchCV(clf, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=10)\n",
    "# random_search = GridSearchCV(clf, param_grid=param_dist, cv=10)\n",
    "\n",
    "random_search.fit(X_single_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "leaves = random_search.best_params_['num_leaves']\n",
    "feature = random_search.best_params_['feature_fraction']\n",
    "est = random_search.best_params_['n_estimators']\n",
    "bag = random_search.best_params_['bagging_fraction']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "51\n",
      "0.65\n",
      "300\n",
      "0.65\n"
     ]
    }
   ],
   "source": [
    "print(leaves)\n",
    "print(feature)\n",
    "print(est)\n",
    "print(bag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def remove_single_feature(X_train, X_test):\n",
    "    cols = X_train.columns\n",
    "    single_val = []\n",
    "    for index in cols:\n",
    "        if (len(X_train[index].unique()) == 1):\n",
    "            single_val.append(index)\n",
    "\n",
    "    test_val = []\n",
    "    for index in single_val:\n",
    "        if (len(X_test[index].unique()) == 1):\n",
    "            test_val.append(index)\n",
    "            \n",
    "    single_feature = list(set(single_val).intersection(set(test_val)))\n",
    "    \n",
    "    X_single_train = X_train.drop(columns=single_feature)\n",
    "    X_single_test = X_test.drop(columns=single_feature)\n",
    "\n",
    "    return X_single_train, X_single_test, single_feature\n",
    "\n",
    "def log_small(X_train, X_test):\n",
    "    X_single_train, X_single_test, single_feature = remove_single_feature(X_train, X_test)\n",
    "    \n",
    "    small_cols = []\n",
    "    for i in X_single_train.columns:\n",
    "        count = sum(X_single_train[i] < 0.1)\n",
    "        if count > .9*5331:\n",
    "            small_cols.append(i)\n",
    "\n",
    "    log_columns = list(set(small_cols).difference(set(single_feature)))\n",
    "\n",
    "    epsilon_X_train = X_single_train.replace(0, 10 ** (-100))\n",
    "    epsilon_X_test = X_single_test.replace(0, 10 ** (-100))\n",
    "    for col in log_columns:\n",
    "        epsilon_X_train[col] = epsilon_X_train[col].apply(np.log)\n",
    "        epsilon_X_test[col] = epsilon_X_test[col].apply(np.log)\n",
    "    return epsilon_X_train, epsilon_X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('lightgbm score: ', 0.026587896358612223, '(', 0.0012390211992261246, ')')\n"
     ]
    }
   ],
   "source": [
    "predictions = train_lgb(epsilon_X_train, epsilon_X_test, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_X_train, new_X_test = log_small(X_train, X_test)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
