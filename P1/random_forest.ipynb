{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression as Lin_Reg\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cmx\n",
    "import matplotlib.colors as colors\n",
    "import scipy as sp\n",
    "from sklearn.linear_model import RidgeCV, Ridge, LassoCV, LassoLarsCV\n",
    "%matplotlib inline\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training and test sets (assumes you have these in current working directory)\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "test = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "      <th>Target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612863</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.217791</td>\n",
       "      <td>0.233629</td>\n",
       "      <td>0.540962</td>\n",
       "      <td>0.901355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.075030</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.246119</td>\n",
       "      <td>0.143860</td>\n",
       "      <td>0.525384</td>\n",
       "      <td>0.913550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.996325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.436279</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.119091</td>\n",
       "      <td>0.162869</td>\n",
       "      <td>0.361124</td>\n",
       "      <td>0.884824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.997969</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.392743</td>\n",
       "      <td>0.377302</td>\n",
       "      <td>0.613776</td>\n",
       "      <td>0.977236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.998278</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364235</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.096297</td>\n",
       "      <td>0.166459</td>\n",
       "      <td>0.408322</td>\n",
       "      <td>0.921138</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 253 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Feat 1    Feat 2    Feat 3    Feat 4    Feat 5    Feat 6  Feat 7  \\\n",
       "0   1  0.998952  0.174118  0.999211  0.996460  0.133333  0.057143   0.000   \n",
       "1   2  0.999445  0.174118  0.999329  0.997079  0.133333  0.000000   0.000   \n",
       "2   3  0.998759  0.000000  0.997260  0.996325  0.000000  0.085714   0.125   \n",
       "3   4  0.999619  0.174118  0.997969  0.997321  0.266667  0.057143   0.125   \n",
       "4   5  0.998278  0.174118  0.998427  0.996269  0.200000  0.000000   0.000   \n",
       "\n",
       "   Feat 8  Feat 9  ...  Feat 243  Feat 244  Feat 245  Feat 246  Feat 247  \\\n",
       "0     0.0     0.0  ...       0.0       0.0         0  0.612863  0.026812   \n",
       "1     0.0     0.0  ...       0.0       0.0         0  0.688941  0.075030   \n",
       "2     0.0     0.0  ...       0.0       0.0         0  0.156863  0.436279   \n",
       "3     0.0     0.0  ...       0.0       0.0         0  0.709647  0.075472   \n",
       "4     0.0     0.0  ...       0.0       0.0         0  0.364235  0.041818   \n",
       "\n",
       "   Feat 248  Feat 249  Feat 250  Feat 251    Target  \n",
       "0     0.522  0.217791  0.233629  0.540962  0.901355  \n",
       "1     0.704  0.246119  0.143860  0.525384  0.913550  \n",
       "2     0.000  0.119091  0.162869  0.361124  0.884824  \n",
       "3     0.513  0.392743  0.377302  0.613776  0.977236  \n",
       "4     0.200  0.096297  0.166459  0.408322  0.921138  \n",
       "\n",
       "[5 rows x 253 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect training set\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 242</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.997841</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728471</td>\n",
       "      <td>0.054397</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.053998</td>\n",
       "      <td>0.667391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497255</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.165514</td>\n",
       "      <td>0.101973</td>\n",
       "      <td>0.506650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.997376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.192069</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.498784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654118</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.451252</td>\n",
       "      <td>0.164180</td>\n",
       "      <td>0.774466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.160433</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    Feat 1    Feat 2    Feat 3    Feat 4    Feat 5  Feat 6  Feat 7  \\\n",
       "0   1  0.999849  0.174118  0.999819  0.997841  0.133333     0.2     0.0   \n",
       "1   2  0.999958  0.164706  1.000000  0.996741  0.066667     0.0     0.0   \n",
       "2   3  0.999666  0.174118  0.999479  0.997376  0.000000     0.0     0.0   \n",
       "3   4  0.999735  0.174118  0.999655  0.997173  0.133333     0.0     0.0   \n",
       "4   5  0.999806  0.164706  0.999551  0.997234  0.000000     0.0     0.0   \n",
       "\n",
       "   Feat 8    Feat 9  ...  Feat 242  Feat 243  Feat 244  Feat 245  Feat 246  \\\n",
       "0     0.0  0.000000  ...       0.0       0.0       0.0         0  0.728471   \n",
       "1     0.0  0.000000  ...       0.0       0.0       0.0         0  0.497255   \n",
       "2     0.0  0.000000  ...       0.0       0.0       0.0         0  0.688941   \n",
       "3     0.0  0.363636  ...       0.0       0.0       0.0         0  0.654118   \n",
       "4     0.0  0.000000  ...       0.0       0.0       0.0         0  0.627451   \n",
       "\n",
       "   Feat 247  Feat 248  Feat 249  Feat 250  Feat 251  \n",
       "0  0.054397     0.649  0.416164  0.053998  0.667391  \n",
       "1  0.037736     0.375  0.165514  0.101973  0.506650  \n",
       "2  0.019309     1.000  0.192069  0.120700  0.498784  \n",
       "3  0.019089     0.333  0.451252  0.164180  0.774466  \n",
       "4  0.160433     0.882  0.147407  0.000000  0.481240  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect test set\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Explore distribution of target\n",
    "plt.hist(train['Target'], bins = 100)\n",
    "plt.title(\"Distribution of Dependent Variable\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>Feat 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 242</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.998952</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612863</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.217791</td>\n",
       "      <td>0.233629</td>\n",
       "      <td>0.540962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999445</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.075030</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.246119</td>\n",
       "      <td>0.143860</td>\n",
       "      <td>0.525384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.998759</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.996325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.436279</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.119091</td>\n",
       "      <td>0.162869</td>\n",
       "      <td>0.361124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999619</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.997969</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.392743</td>\n",
       "      <td>0.377302</td>\n",
       "      <td>0.613776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.998278</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364235</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.096297</td>\n",
       "      <td>0.166459</td>\n",
       "      <td>0.408322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feat 1    Feat 2    Feat 3    Feat 4    Feat 5    Feat 6  Feat 7  Feat 8  \\\n",
       "0  0.998952  0.174118  0.999211  0.996460  0.133333  0.057143   0.000     0.0   \n",
       "1  0.999445  0.174118  0.999329  0.997079  0.133333  0.000000   0.000     0.0   \n",
       "2  0.998759  0.000000  0.997260  0.996325  0.000000  0.085714   0.125     0.0   \n",
       "3  0.999619  0.174118  0.997969  0.997321  0.266667  0.057143   0.125     0.0   \n",
       "4  0.998278  0.174118  0.998427  0.996269  0.200000  0.000000   0.000     0.0   \n",
       "\n",
       "   Feat 9   Feat 10  ...  Feat 242  Feat 243  Feat 244  Feat 245  Feat 246  \\\n",
       "0     0.0  0.000000  ...  0.000000       0.0       0.0         0  0.612863   \n",
       "1     0.0  0.000000  ...  0.000000       0.0       0.0         0  0.688941   \n",
       "2     0.0  0.000000  ...  0.166667       0.0       0.0         0  0.156863   \n",
       "3     0.0  0.041667  ...  0.000000       0.0       0.0         0  0.709647   \n",
       "4     0.0  0.000000  ...  0.000000       0.0       0.0         0  0.364235   \n",
       "\n",
       "   Feat 247  Feat 248  Feat 249  Feat 250  Feat 251  \n",
       "0  0.026812     0.522  0.217791  0.233629  0.540962  \n",
       "1  0.075030     0.704  0.246119  0.143860  0.525384  \n",
       "2  0.436279     0.000  0.119091  0.162869  0.361124  \n",
       "3  0.075472     0.513  0.392743  0.377302  0.613776  \n",
       "4  0.041818     0.200  0.096297  0.166459  0.408322  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split training set into X and y (removing first column containing IDs)\n",
    "X_train = train.iloc[:, 1:-1]\n",
    "y_train = train.iloc[:, -1]\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define function to compute RMSE\n",
    "def scoreRMSE(predictor, X, true_y):\n",
    "    predictions = predictor.predict(X)\n",
    "    return np.sqrt(mean_squared_error(predictions, true_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat 1</th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>Feat 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 242</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.999849</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999819</td>\n",
       "      <td>0.997841</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.728471</td>\n",
       "      <td>0.054397</td>\n",
       "      <td>0.649</td>\n",
       "      <td>0.416164</td>\n",
       "      <td>0.053998</td>\n",
       "      <td>0.667391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.999958</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996741</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.497255</td>\n",
       "      <td>0.037736</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.165514</td>\n",
       "      <td>0.101973</td>\n",
       "      <td>0.506650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999666</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>0.997376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.019309</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.192069</td>\n",
       "      <td>0.120700</td>\n",
       "      <td>0.498784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999735</td>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999655</td>\n",
       "      <td>0.997173</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363636</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.654118</td>\n",
       "      <td>0.019089</td>\n",
       "      <td>0.333</td>\n",
       "      <td>0.451252</td>\n",
       "      <td>0.164180</td>\n",
       "      <td>0.774466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999806</td>\n",
       "      <td>0.164706</td>\n",
       "      <td>0.999551</td>\n",
       "      <td>0.997234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.627451</td>\n",
       "      <td>0.160433</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.147407</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.481240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 251 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feat 1    Feat 2    Feat 3    Feat 4    Feat 5  Feat 6  Feat 7  Feat 8  \\\n",
       "0  0.999849  0.174118  0.999819  0.997841  0.133333     0.2     0.0     0.0   \n",
       "1  0.999958  0.164706  1.000000  0.996741  0.066667     0.0     0.0     0.0   \n",
       "2  0.999666  0.174118  0.999479  0.997376  0.000000     0.0     0.0     0.0   \n",
       "3  0.999735  0.174118  0.999655  0.997173  0.133333     0.0     0.0     0.0   \n",
       "4  0.999806  0.164706  0.999551  0.997234  0.000000     0.0     0.0     0.0   \n",
       "\n",
       "     Feat 9   Feat 10  ...  Feat 242  Feat 243  Feat 244  Feat 245  Feat 246  \\\n",
       "0  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.728471   \n",
       "1  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.497255   \n",
       "2  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.688941   \n",
       "3  0.363636  0.166667  ...       0.0       0.0       0.0         0  0.654118   \n",
       "4  0.000000  0.000000  ...       0.0       0.0       0.0         0  0.627451   \n",
       "\n",
       "   Feat 247  Feat 248  Feat 249  Feat 250  Feat 251  \n",
       "0  0.054397     0.649  0.416164  0.053998  0.667391  \n",
       "1  0.037736     0.375  0.165514  0.101973  0.506650  \n",
       "2  0.019309     1.000  0.192069  0.120700  0.498784  \n",
       "3  0.019089     0.333  0.451252  0.164180  0.774466  \n",
       "4  0.160433     0.882  0.147407  0.000000  0.481240  \n",
       "\n",
       "[5 rows x 251 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove first column to make predictions\n",
    "X_test = test.iloc[:, 1:]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 1 for tuning parameters: remove redundant predictors\n",
    "def remove_single_feature(X_train, X_test):\n",
    "    cols = X_train.columns\n",
    "    single_val = []\n",
    "    for index in cols:\n",
    "        if (len(X_train[index].unique()) == 1):\n",
    "            single_val.append(index)\n",
    "\n",
    "    test_val = []\n",
    "    for index in single_val:\n",
    "        if (len(X_test[index].unique()) == 1):\n",
    "            test_val.append(index)\n",
    "            \n",
    "    single_feature = list(set(single_val).intersection(set(test_val)))\n",
    "    X_remove_train = X_train.drop(columns=single_feature)\n",
    "    X_remove_test = X_test.drop(columns=single_feature)\n",
    "    \n",
    "    return X_remove_train, X_remove_test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 2 for tuning parameters: remove high collinearity features\n",
    "def remove_high_correlation(X_train, X_test):\n",
    "    corr_matrix = X_train.corr().abs()\n",
    "    high_corr_var=np.where(corr_matrix>0.95)\n",
    "    high_corr_var=[(corr_matrix.columns[x],corr_matrix.columns[y]) for x,y in zip(*high_corr_var) if x!=y and x<y]\n",
    "    \n",
    "    remove_vars = [i[0] for i in high_corr_var]\n",
    "    \n",
    "    X_corr_train = X_train.drop(columns=remove_vars)\n",
    "    X_corr_test = X_test.drop(columns=remove_vars)\n",
    "    return X_corr_train, X_corr_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Option 3 for tuning parameters: PCA\n",
    "def scale_and_pca(X_train, X_test, pca_val):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train.values)\n",
    "    X_train_scale = scaler.transform(X_train.values)\n",
    "    X_test_scale = scaler.transform(X_test.values)\n",
    "    \n",
    "    pca = PCA(pca_val)\n",
    "    \n",
    "    pca.fit(X_train_scale)\n",
    "    \n",
    "    X_train_scale_pca = pca.transform(X_train_scale)\n",
    "    X_test_scale_pca = pca.transform(X_test_scale)\n",
    "    \n",
    "    return X_train_scale_pca, X_test_scale_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_original_train = X_train\n",
    "X_original_test = X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_single_train, X_single_test = remove_single_feature(X_original_train, X_original_test)\n",
    "\n",
    "X_correlation_train, X_correlation_test = remove_high_correlation(X_original_train, X_original_test)\n",
    "\n",
    "X_pca_train, X_pca_test = scale_and_pca(X_single_train, X_single_test, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feat 2</th>\n",
       "      <th>Feat 3</th>\n",
       "      <th>Feat 4</th>\n",
       "      <th>Feat 5</th>\n",
       "      <th>Feat 6</th>\n",
       "      <th>Feat 7</th>\n",
       "      <th>Feat 8</th>\n",
       "      <th>Feat 9</th>\n",
       "      <th>Feat 10</th>\n",
       "      <th>Feat 11</th>\n",
       "      <th>...</th>\n",
       "      <th>Feat 242</th>\n",
       "      <th>Feat 243</th>\n",
       "      <th>Feat 244</th>\n",
       "      <th>Feat 245</th>\n",
       "      <th>Feat 246</th>\n",
       "      <th>Feat 247</th>\n",
       "      <th>Feat 248</th>\n",
       "      <th>Feat 249</th>\n",
       "      <th>Feat 250</th>\n",
       "      <th>Feat 251</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999211</td>\n",
       "      <td>0.996460</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.612863</td>\n",
       "      <td>0.026812</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.217791</td>\n",
       "      <td>0.233629</td>\n",
       "      <td>0.540962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.999329</td>\n",
       "      <td>0.997079</td>\n",
       "      <td>0.133333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.688941</td>\n",
       "      <td>0.075030</td>\n",
       "      <td>0.704</td>\n",
       "      <td>0.246119</td>\n",
       "      <td>0.143860</td>\n",
       "      <td>0.525384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.997260</td>\n",
       "      <td>0.996325</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.085714</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.156863</td>\n",
       "      <td>0.436279</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.119091</td>\n",
       "      <td>0.162869</td>\n",
       "      <td>0.361124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.997969</td>\n",
       "      <td>0.997321</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.057143</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.709647</td>\n",
       "      <td>0.075472</td>\n",
       "      <td>0.513</td>\n",
       "      <td>0.392743</td>\n",
       "      <td>0.377302</td>\n",
       "      <td>0.613776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.174118</td>\n",
       "      <td>0.998427</td>\n",
       "      <td>0.996269</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.364235</td>\n",
       "      <td>0.041818</td>\n",
       "      <td>0.200</td>\n",
       "      <td>0.096297</td>\n",
       "      <td>0.166459</td>\n",
       "      <td>0.408322</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 242 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Feat 2    Feat 3    Feat 4    Feat 5    Feat 6  Feat 7  Feat 8  Feat 9  \\\n",
       "0  0.174118  0.999211  0.996460  0.133333  0.057143   0.000     0.0     0.0   \n",
       "1  0.174118  0.999329  0.997079  0.133333  0.000000   0.000     0.0     0.0   \n",
       "2  0.000000  0.997260  0.996325  0.000000  0.085714   0.125     0.0     0.0   \n",
       "3  0.174118  0.997969  0.997321  0.266667  0.057143   0.125     0.0     0.0   \n",
       "4  0.174118  0.998427  0.996269  0.200000  0.000000   0.000     0.0     0.0   \n",
       "\n",
       "    Feat 10  Feat 11  ...  Feat 242  Feat 243  Feat 244  Feat 245  Feat 246  \\\n",
       "0  0.000000      0.0  ...  0.000000       0.0       0.0         0  0.612863   \n",
       "1  0.000000      0.0  ...  0.000000       0.0       0.0         0  0.688941   \n",
       "2  0.000000      0.0  ...  0.166667       0.0       0.0         0  0.156863   \n",
       "3  0.041667      0.0  ...  0.000000       0.0       0.0         0  0.709647   \n",
       "4  0.000000      0.0  ...  0.000000       0.0       0.0         0  0.364235   \n",
       "\n",
       "   Feat 247  Feat 248  Feat 249  Feat 250  Feat 251  \n",
       "0  0.026812     0.522  0.217791  0.233629  0.540962  \n",
       "1  0.075030     0.704  0.246119  0.143860  0.525384  \n",
       "2  0.436279     0.000  0.119091  0.162869  0.361124  \n",
       "3  0.075472     0.513  0.392743  0.377302  0.613776  \n",
       "4  0.041818     0.200  0.096297  0.166459  0.408322  \n",
       "\n",
       "[5 rows x 242 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test = X_correlation_train, X_correlation_test\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('R^2 Values for Train Using Random Forest Regression:', [0.031750533396099234, 0.05388533064967671, 0.07407603386603712, 0.10476619795599862, 0.13909162096272754, 0.1760398542465884, 0.21525562007445576, 0.2648725282118346, 0.31121776895275, 0.36068921779001084, 0.41622042162935924, 0.4560386039683604, 0.4967518222088544, 0.5136279384239373, 0.5662277427141087, 0.5836520977923747, 0.6443467729982209, 0.6598124741254328, 0.6633148047297134, 0.6839126700354621, 0.6968243625886705, 0.7119436685032619, 0.749681947113993, 0.7325673843881378])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_train_rf = []\n",
    "\n",
    "# check multiple depths to see which depth is best\n",
    "for i in range(1, 25):\n",
    "    rf_reg = RandomForestRegressor(max_depth=i)\n",
    "    rf_reg.fit(X_train, y_train)\n",
    "    rf_yhat_train = rf_reg.predict(X_train)\n",
    "\n",
    "    r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "\n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Best Depth for Random Forest Tree Depth:', 23)\n"
     ]
    }
   ],
   "source": [
    "# get best depth\n",
    "import operator\n",
    "index, value = max(enumerate(r2_train_rf), key=operator.itemgetter(1))\n",
    "best_depth = index+1\n",
    "print('Best Depth for Random Forest Tree Depth:', best_depth )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('R^2 Values for Train Using Random Forest Regression:', [0.031750533396099234, 0.05388533064967671, 0.07407603386603712, 0.10476619795599862, 0.13909162096272754, 0.1760398542465884, 0.21525562007445576, 0.2648725282118346, 0.31121776895275, 0.36068921779001084, 0.41622042162935924, 0.4560386039683604, 0.4967518222088544, 0.5136279384239373, 0.5662277427141087, 0.5836520977923747, 0.6443467729982209, 0.6598124741254328, 0.6633148047297134, 0.6839126700354621, 0.6968243625886705, 0.7119436685032619, 0.749681947113993, 0.7325673843881378])\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning Random Forest: Initial Run with max_depth set to the optimal depth from shotgun approach\n",
    "r2_train_rf_finetune = []\n",
    "\n",
    "rf_reg = RandomForestRegressor(max_depth=best_depth)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "rf_yhat_train = rf_reg.predict(X_train)\n",
    "r2_train_rf_finetune.append( r2_score(y_train, rf_yhat_train))\n",
    "\n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('R^2 Values for Train Using Random Forest Regression:', [0.29549315601478954, 0.49728736404648344, 0.6667514534761019, 0.7132474744134484, 0.7449410457219462, 0.755856813407595, 0.7743333724362064, 0.7751069428516201])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# step 1: fine tune the number of trees\n",
    "r2_train_rf_trees = []\n",
    "\n",
    "# create list of tree numbers we will test\n",
    "trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "\n",
    "# test the tree numbers keeping max_depth at best_depth\n",
    "for n_trees in trees:\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees, max_depth=best_depth, max_features='auto')\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "\n",
    "    r2_train_rf_trees.append(r2_score(y_train, rf_yhat_train))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_trees)\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('RandomForest Best Number of Trees:', 128)\n",
      "('R^2 Value:', 0.7751069428516201)\n"
     ]
    }
   ],
   "source": [
    "# get best number of trees\n",
    "index, value = max(enumerate(r2_train_rf_trees), key=operator.itemgetter(1))\n",
    "best_tree = trees[index]\n",
    "print('RandomForest Best Number of Trees:',best_tree)\n",
    "print('R^2 Value:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# find best number of maximum predictors to consider\n",
    "# note: we ultimately decided this parameter had no significant effect on model accuracy\n",
    "\n",
    "r2_train_rf_feat = []\n",
    "\n",
    "for i in range(186, 252):\n",
    "    rf = RandomForestRegressor(n_estimators=best_tree, max_depth=best_depth, max_features=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    r2_train_rf_feat.append(r2_score(y_train, rf_yhat_train))\n",
    "# got through 185 and the best was 80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get best number of predictors and best R^2 value\n",
    "index, value = max(enumerate(r2_train_rf_feat), key=operator.itemgetter(1))\n",
    "best_num_predictors = index+1\n",
    "print('RandomForest Number of Predictors for Best value:', best_num_predictors)\n",
    "print('Final Best R^2 Value:',value)\n",
    "print (len(r2_train_rf_feat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RMSE:  0.013275724172648003\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestRegressor(n_estimators=best_tree, max_depth=best_depth)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print \"Training RMSE: \", scoreRMSE(rf, X_train, y_train)\n",
    "# 0.012867567452659339\n",
    "# 0.012763220680344514"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Make predictions with our model\n",
    "predictions = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.939030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.913262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.915379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.931399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.936057</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Id  Predicted\n",
       "0  1   0.939030\n",
       "1  2   0.913262\n",
       "2  3   0.915379\n",
       "3  4   0.931399\n",
       "4  5   0.936057"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format predictions to be compatible with Kaggle upload\n",
    "sample_submission = pd.DataFrame(data=predictions, columns=['Predicted'])\n",
    "sample_submission.insert(0, \"Id\", range(1, 1 + X_test.shape[0]))\n",
    "sample_submission['Id'] = sample_submission['Id'].astype(str)\n",
    "sample_submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save predictions to .csv file for upload to Kaggle\n",
    "sample_submission.to_csv(\"sample_submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
