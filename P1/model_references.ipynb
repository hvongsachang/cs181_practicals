{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 109A/STAT 121A/AC 209A/CSCI E-109A: \n",
    "# Final Project: Group 31\n",
    "\n",
    "**Harvard University**<br/>\n",
    "**Fall 2017**<br/>\n",
    "**Instructors**: Pavlos Protopapas, Kevin Rader, Rahul Dave, Margo Levine\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IhnSik\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "#import pydotplus\n",
    "#import io\n",
    "from sklearn.tree import export_graphviz\n",
    "from IPython.display import Image\n",
    "from IPython.display import display\n",
    "from sklearn.metrics import accuracy_score\n",
    "import datetime as DT\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.utils import resample\n",
    "from scipy import stats\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spotify Predictors Only"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shotgun Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv of spotify predictors\n",
    "df = pd.read_csv('./spotify_preds_csv2.csv')\n",
    "df = df.dropna()\n",
    "df = df.drop(['Unnamed: 0'], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# split data\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(df)) < 0.75\n",
    "data_train = df[msk]\n",
    "data_test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "column_headers = list(data_train.columns.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get variables\n",
    "X_train = data_train.iloc[:,6:]\n",
    "y_train = data_train.iloc[:, 1]\n",
    "\n",
    "X_test = data_test.iloc[:,6:]\n",
    "y_test = data_test.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Linear Regression: 0.169149915072 0.179534112657\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "X_train2 = sm.add_constant(X_train.values)\n",
    "model = sm.OLS(y_train.values, X_train2)\n",
    "results = model.fit()\n",
    "\n",
    "y_hat_train = results.predict(X_train2)\n",
    "\n",
    "# test case\n",
    "X_test2 = sm.add_constant(X_test.values)\n",
    "y_hat_test = results.predict(X_test2)\n",
    "\n",
    "r2_score_train = r2_score(y_train, y_hat_train) \n",
    "r2_score_test = r2_score(y_test, y_hat_test)\n",
    "\n",
    "print('R^2 Values for Train, Test Using Linear Regression:', r2_score_train, r2_score_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Polynomial Regression: [0.22894924317795406] [0.19789980160737619]\n"
     ]
    }
   ],
   "source": [
    "# polynomial term regression\n",
    "from sklearn import linear_model\n",
    "r2_train_poly = []\n",
    "r2_test_poly = []\n",
    "\n",
    "# make dataframes to add polynomial terms to\n",
    "cont = ['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_num_artists', 'avg_num_markets']\n",
    "X_binary_only = X_train.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_test_bin_only = X_test.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_poly = X_binary_only.copy()\n",
    "X_test_poly = X_test_bin_only.copy()\n",
    "\n",
    "X_poly_test_all = X_test.copy()\n",
    "X_poly_train_all = X_train.copy()\n",
    "\n",
    "# function to create and add polynomial terms to dataframe\n",
    "def add_poly_features(train, test, poly_train, poly_test, polylist):\n",
    "    for col in polylist:\n",
    "        for i in range(2,4):\n",
    "            poly_train[col + '_' + str(i)] = train[col]**i\n",
    "            poly_test[col + '_' + str(i)] = test[col]**i\n",
    "\n",
    "add_poly_features(X_train, X_test, X_poly_train_all, X_poly_test_all,cont)\n",
    "\n",
    "# polynomial term regression \n",
    "poly_regression_model = linear_model.LinearRegression(fit_intercept=False)\n",
    "poly_regression_model.fit(X_poly_train_all, y_train)\n",
    "\n",
    "y_hat_train = poly_regression_model.predict(X_poly_train_all)\n",
    "y_hat_test = poly_regression_model.predict(X_poly_test_all)\n",
    "\n",
    "\n",
    "r2_train_poly.append( r2_score(y_train, y_hat_train))\n",
    "r2_test_poly.append( r2_score(y_test, y_hat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Polynomial Regression:', r2_train_poly, r2_test_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using KNN Regression: [0.99999999826605368, 0.67361557405130701, 0.26014861730618322, 0.14666628473394638, 0.12441822659635149, 0.042620591885406456, 0.029105850221909146, 0.022963572284714795, 0.013139851669411118, 0.011592111214729361, 0.0092869321588529008, 0.0077948862622220227, 0.0073745784743184384, 0.0056233810101773418]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using KNN Regression: [-0.75715473073802242, -0.25301680053630093, -0.30348630520483377, -0.094250067982748709, -0.12328060001080909, -0.021899414008623497, -0.013522963401996657, 0.0045474078918134042, 0.0031360746980091392, 0.0017065831673064302, 0.0013485495695024774, 0.0014863803700982947, 0.00016419258602440312, -0.00075057625934760175]\n"
     ]
    }
   ],
   "source": [
    "# knn regression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "# try multiple K's\n",
    "K = [1, 2, 4,8, 10, 50, 100, 250, 500, 600, 700, 800, 900, 1000]\n",
    "r2_test_knn = []\n",
    "r2_train_knn = []\n",
    "\n",
    "# try each different K and calculate R^2\n",
    "for i,k in enumerate(K): \n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    predicted_pickups_train = knn_model.predict(X_train)\n",
    "    predicted_pickups = knn_model.predict(X_test)\n",
    "\n",
    "    r2_train_knn.append( r2_score(y_train, predicted_pickups_train))\n",
    "    r2_test_knn.append( r2_score(y_test, predicted_pickups))\n",
    "    \n",
    "    \n",
    "print('R^2 Values for Train Using KNN Regression:', r2_train_knn)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using KNN Regression:', r2_test_knn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.49720296756434346, 0.61270131485010926, 0.68325744938432675, 0.67393279843134068, 0.72210693690258476, 0.76032229514454808, 0.82802319507749478, 0.89219881258399536, 0.8249767766794609, 0.91741728542031664, 0.84918705143797346, 0.80188428891226848, 0.80126643347813964, 0.79903329718948535, 0.83801613983253065, 0.8615756848017454, 0.92325586257123493, 0.8403246954524074, 0.93468703982697143]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.065688530132135381, 0.11686894621887656, 0.24312942359278267, 0.25580666456779466, 0.26659964595678221, 0.36562212711641229, 0.30701531979506791, 0.29929058898637073, 0.35091131308104861, 0.24928732729333758, 0.26858970989981312, 0.2692000957426397, 0.22855920080718684, 0.34740277432435152, 0.27613072857891741, 0.21208542049379497, 0.32475518293240679, 0.2865265024936684, 0.28830233748470802]\n"
     ]
    }
   ],
   "source": [
    "# random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "# check multiple depths to see which depth is best\n",
    "for i in range(1, 20):\n",
    "    rf_reg = RandomForestRegressor(max_depth=i)\n",
    "    rf_reg.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf_reg.predict(X_train)\n",
    "    rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "    r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf.append( r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth for Random Forest Tree Depth: 6\n"
     ]
    }
   ],
   "source": [
    "# get best depth\n",
    "import operator\n",
    "index, value = max(enumerate(r2_test_rf), key=operator.itemgetter(1))\n",
    "best_depth = index+1\n",
    "print('Best Depth for Random Forest Tree Depth:', best_depth )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge and Lasso for Polynomial Term Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge train R2:  0.311635637957\n",
      "Ridge test R2 0.263143609467\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression on Polynomial Term Regression\n",
    "lambdas = [.001,.005,1,5,10,50,100,500,1000]    \n",
    "ridge = RidgeCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "ridge.fit(X_poly_train_all, y_train)\n",
    "print(\"Ridge train R2: \", ridge.score(X_poly_train_all, y_train))\n",
    "print('Ridge test R2', ridge.score(X_poly_test_all, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IhnSik\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso train R2:  0.309110797466\n",
      "Lasso test R2 0.268284143325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IhnSik\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression on Polynomial Term Regression\n",
    "lasso = LassoCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "lasso.fit(X_poly_train_all, y_train)\n",
    "print(\"Lasso train R2: \", lasso.score(X_poly_train_all, y_train))\n",
    "print('Lasso test R2', lasso.score(X_poly_test_all, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Random Forest Regression: [0.82293769375947434] [0.31770676189595115]\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning Random Forest: Initial Run with max_depth set to the optimal depth from shotgun approach\n",
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "rf_reg = RandomForestRegressor(max_depth=best_depth)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "rf_yhat_train = rf_reg.predict(X_train)\n",
    "rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "r2_test_rf.append( r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Random Forest Regression:', r2_train_rf, r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.54390777801011136, 0.74915188465836335, 0.68857360331932815, 0.66173815567878069, 0.83747904942944829, 0.78575995159604661, 0.80893574377847954, 0.78342305887328823]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.15396519201018743, 0.16246121247554413, 0.24043659131667328, 0.32963429252432519, 0.2785371021681623, 0.30173022605065747, 0.25964668576958727, 0.28956393856307283]\n"
     ]
    }
   ],
   "source": [
    "# step 1: fine tune the number of trees\n",
    "r2_train_rf_trees = []\n",
    "r2_test_rf_trees = []\n",
    "\n",
    "# create list of tree numbers we will test\n",
    "trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "\n",
    "# test the tree numbers keeping max_depth at 9\n",
    "for n_trees in trees:\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees, max_depth=best_depth, max_features='auto')\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_trees.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_trees.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_trees)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Best Number of Trees: 8\n",
      "R^2 Value: 0.329634292524\n"
     ]
    }
   ],
   "source": [
    "# get best number of trees\n",
    "index, value = max(enumerate(r2_test_rf_trees), key=operator.itemgetter(1))\n",
    "best_tree = trees[index]\n",
    "print('RandomForest Best Number of Trees:',best_tree)\n",
    "print('R^2 Value:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.81749611921464682, 0.77321846476908007, 0.78819462911672866, 0.816925271008485, 0.87678836077399691, 0.83477997990957764, 0.87500109687797534, 0.87913004926886285, 0.88820112466808265, 0.85992854321804202, 0.8924926560477211, 0.87891394254210442, 0.82457090459714277, 0.8451926191871838, 0.91019444568084384, 0.85959105566094851, 0.86102047310496765, 0.86257570783480808, 0.85157693727582018, 0.84752315378962051, 0.86590999354425557, 0.86833763456460822]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.21009750906712221, 0.21443955123969971, 0.20966451049282442, 0.19029712386338726, 0.24225359205778041, 0.27066520483498713, 0.25029078641046187, 0.23058538778632154, 0.23860257884132918, 0.26594228903196993, 0.29036814295350932, 0.24813294051505774, 0.26720846088508354, 0.31264175037730524, 0.2455125911463204, 0.27811986532747734, 0.27167901959511009, 0.23134570775926233, 0.27702489305262901, 0.31034805785537567, 0.29927159732389319, 0.26509338805481886]\n"
     ]
    }
   ],
   "source": [
    "# step 2: fine tune the number of predictors used\n",
    "r2_train_rf_feat = []\n",
    "r2_test_rf_feat = []\n",
    "\n",
    "# 23 is the maximum number of predictors we have\n",
    "for i in range(1, 23):\n",
    "    rf = RandomForestRegressor(n_estimators=32, max_depth=9, max_features=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_feat.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_feat.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_feat)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Number of Predictors for Best value: 14\n",
      "Best R^2 Value Using Only Spotify Predictors: 0.312641750377\n"
     ]
    }
   ],
   "source": [
    "# get best number of predictors\n",
    "import operator\n",
    "index, value = max(enumerate(r2_test_rf_feat), key=operator.itemgetter(1))\n",
    "print('RandomForest Number of Predictors for Best value:',index+1)\n",
    "print('Best R^2 Value Using Only Spotify Predictors:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined Predictors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read csv that combines previous csv from spotify with few additional columns of additional predictors\n",
    "df = pd.read_csv('./final_dataset.csv')\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split data\n",
    "np.random.seed(9001)\n",
    "msk = np.random.rand(len(df)) < 0.75\n",
    "data_train = df[msk]\n",
    "data_test = df[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get predictor list\n",
    "column_headers = list(data_train.columns.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shotgun Phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get variables\n",
    "X_train = data_train.iloc[:,6:]\n",
    "y_train = data_train.iloc[:, 1]\n",
    "\n",
    "X_test = data_test.iloc[:,6:]\n",
    "y_test = data_test.iloc[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Linear Regression: 0.188983912582 0.12729231813\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression\n",
    "X_train2 = sm.add_constant(X_train.values)\n",
    "model = sm.OLS(y_train.values, X_train2)\n",
    "results = model.fit()\n",
    "\n",
    "y_hat_train = results.predict(X_train2)\n",
    "\n",
    "# test case\n",
    "X_test2 = sm.add_constant(X_test.values)\n",
    "y_hat_test = results.predict(X_test2)\n",
    "\n",
    "r2_score_train = r2_score(y_train, y_hat_train) \n",
    "r2_score_test = r2_score(y_test, y_hat_test)\n",
    "\n",
    "print('R^2 Values for Train, Test Using Linear Regression:', r2_score_train, r2_score_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Polynomial Regression: [0.22310947907083678] [0.19655342308010126]\n"
     ]
    }
   ],
   "source": [
    "# Polynomial Term Regression\n",
    "from sklearn import linear_model\n",
    "r2_train_poly = []\n",
    "r2_test_poly = []\n",
    "\n",
    "# set up dataframe to add polynomial terms to\n",
    "cont = ['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_danceability', 'avg_energy', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_duration_ms', 'avg_num_artists', 'avg_num_markets']\n",
    "X_binary_only = X_train.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_danceability', 'avg_energy', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_duration_ms', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_test_bin_only = X_test.drop(['avg_album_popularity', 'avg_album_release_year', 'avg_artist_popularity', 'avg_artist_followers', 'num_tracks', 'avg_song_popularity', 'avg_danceability', 'avg_energy', 'avg_loudness', 'avg_speechiness', 'avg_acousticness', 'avg_instrumentalness', 'avg_liveness', 'avg_valence', 'avg_duration_ms', 'avg_num_artists', 'avg_num_markets'], axis=1)\n",
    "X_poly = X_binary_only.copy()\n",
    "X_test_poly = X_test_bin_only.copy()\n",
    "\n",
    "X_poly_test_all = X_test.copy()\n",
    "X_poly_train_all = X_train.copy()\n",
    "\n",
    "# function to create and add polynomial terms to dataframe\n",
    "def add_poly_features(train, test, poly_train, poly_test, polylist):\n",
    "    for col in polylist:\n",
    "        for i in range(2,4):\n",
    "            poly_train[col + '_' + str(i)] = train[col]**i\n",
    "            poly_test[col + '_' + str(i)] = test[col]**i\n",
    "\n",
    "add_poly_features(X_train, X_test, X_poly_train_all, X_poly_test_all,cont)\n",
    "\n",
    "# regress and calculate R^2\n",
    "poly_regression_model = linear_model.LinearRegression(fit_intercept=False)\n",
    "poly_regression_model.fit(X_poly_train_all, y_train)\n",
    "\n",
    "y_hat_train = poly_regression_model.predict(X_poly_train_all)\n",
    "y_hat_test = poly_regression_model.predict(X_poly_test_all)\n",
    "\n",
    "r2_train_poly.append( r2_score(y_train, y_hat_train))\n",
    "r2_test_poly.append( r2_score(y_test, y_hat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Polynomial Regression:', r2_train_poly, r2_test_poly)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using KNN Regression: [0.99999999826605368, 0.70705295578349214, 0.26384447277586165, 0.14062785261746957, 0.16815399746437676, 0.041790871252071704, 0.026784122297934254, 0.022334620712726183, 0.013199508562418361, 0.011615787116215581, 0.0092690893153853926, 0.0079270698554815278, 0.0074171109814979985, 0.0056618388771036976]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using KNN Regression: [-0.87195646189656983, -0.32627859453665375, -0.1542926908927027, -0.089021508792754611, -0.11809935938908334, -0.020776306046869086, -0.010578038605963069, 0.0031685923025387419, 0.0036867169843481928, 0.0026448150105176094, 0.0015801451321187931, 0.0015217888123526535, 0.00056359830487651141, -0.0006410793680169391]\n"
     ]
    }
   ],
   "source": [
    "# KNN Regression: test different K's\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "K = [1, 2, 4,8, 10, 50, 100, 250, 500, 600, 700, 800, 900, 1000]\n",
    "\n",
    "r2_test_knn = []\n",
    "r2_train_knn = []\n",
    "\n",
    "# test different k's and regress\n",
    "for i,k in enumerate(K): \n",
    "    knn_model = KNeighborsRegressor(n_neighbors=k)\n",
    "    knn_model.fit(X_train, y_train)\n",
    "    predicted_pickups_train = knn_model.predict(X_train)\n",
    "    predicted_pickups = knn_model.predict(X_test)\n",
    "\n",
    "    r2_train_knn.append( r2_score(y_train, predicted_pickups_train))\n",
    "    r2_test_knn.append( r2_score(y_test, predicted_pickups))\n",
    "    \n",
    "    \n",
    "print('R^2 Values for Train Using KNN Regression:', r2_train_knn)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using KNN Regression:', r2_test_knn)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.49720296756434346, 0.61053350899380598, 0.67511950828551681, 0.67387294267734843, 0.73276489542719059, 0.76318669077294254, 0.82590310068220496, 0.89548927397264066, 0.82065384409508457, 0.89398625403987209, 0.82760577348070163, 0.79403836942059292, 0.8100563877259388, 0.82224424426050358, 0.85025771122325189, 0.85715368168184147, 0.9331919843632086, 0.80620122624416679, 0.94136130639871862]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.065688530132135381, 0.11955126119857296, 0.23689289946392322, 0.26268485949846965, 0.27210599525123269, 0.31376558972213309, 0.28322097770388877, 0.33781445372311392, 0.35981602438696281, 0.27767797065812116, 0.22661389303616364, 0.2564865245822131, 0.15968107555102107, 0.31209263225671557, 0.24284017786329626, 0.25838381619956918, 0.26517810613637338, 0.25505016476376241, 0.24039207539967111]\n"
     ]
    }
   ],
   "source": [
    "# random forest regression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "# check multiple depths to see which depth is best\n",
    "for i in range(1, 20):\n",
    "    rf_reg = RandomForestRegressor(max_depth=i)\n",
    "    rf_reg.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf_reg.predict(X_train)\n",
    "    rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "    r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf.append( r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Depth for Random Forest Tree Depth: 9\n"
     ]
    }
   ],
   "source": [
    "# get best depth\n",
    "index, value = max(enumerate(r2_test_rf), key=operator.itemgetter(1))\n",
    "best_depth2 = index+1\n",
    "print('Best Depth for Random Forest Tree Depth:', best_depth2 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine Tuning Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge and Lasso on Polynomial Term Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge train R2:  0.326729914555\n",
      "Ridge test R2 0.257295436254\n"
     ]
    }
   ],
   "source": [
    "# Ridge Regression on Polynomial Term Regression\n",
    "lambdas = [.001,.005,1,5,10,50,100,500,1000]    \n",
    "ridge = RidgeCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "ridge.fit(X_poly_train_all, y_train)\n",
    "print(\"Ridge train R2: \", ridge.score(X_poly_train_all, y_train))\n",
    "print('Ridge test R2', ridge.score(X_poly_test_all, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IhnSik\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso train R2:  0.330382769017\n",
      "Lasso test R2 0.223520995991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IhnSik\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:484: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Lasso Regression on Polynomial Term Regression\n",
    "lasso = LassoCV(alphas=lambdas, fit_intercept=False, normalize=True, cv=10)\n",
    "lasso.fit(X_poly_train_all, y_train)\n",
    "print(\"Lasso train R2: \", lasso.score(X_poly_train_all, y_train))\n",
    "print('Lasso test R2', lasso.score(X_poly_test_all, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train, Test Using Random Forest Regression: [0.90189089522031818] [0.23157544697065435]\n"
     ]
    }
   ],
   "source": [
    "# Fine Tuning Random Forest: get R^2 values for optimal depth that we calculated in shotgun approach\n",
    "r2_train_rf = []\n",
    "r2_test_rf = []\n",
    "\n",
    "rf_reg = RandomForestRegressor(max_depth=best_depth2)\n",
    "rf_reg.fit(X_train, y_train)\n",
    "\n",
    "rf_yhat_train = rf_reg.predict(X_train)\n",
    "rf_yhat_test = rf_reg.predict(X_test)\n",
    "\n",
    "r2_train_rf.append( r2_score(y_train, rf_yhat_train))\n",
    "r2_test_rf.append(r2_score(y_test, rf_yhat_test))\n",
    "\n",
    "print('R^2 Values for Train, Test Using Random Forest Regression:', r2_train_rf, r2_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.58601731456312234, 0.80518079006581667, 0.74293370836669848, 0.73025122456148694, 0.90057120880801123, 0.84795860443696702, 0.88083329180459491, 0.85593486474751224]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [-0.013935959307974422, 0.07300285483685709, 0.14399150549967843, 0.31431646702194216, 0.24648467198446888, 0.30167909769024848, 0.26542634682886901, 0.26380393138249736]\n"
     ]
    }
   ],
   "source": [
    "# step 1: fine tuning number of trees\n",
    "r2_train_rf_trees = []\n",
    "r2_test_rf_trees = []\n",
    "\n",
    "# will try various number of trees\n",
    "trees = [2**x for x in range(8)]  # 2, 4, 8, 16, 32, ... \n",
    "\n",
    "# try different trees with optimal depth\n",
    "for n_trees in trees:\n",
    "    rf = RandomForestRegressor(n_estimators=n_trees, max_depth=best_depth2, max_features='auto')\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_trees.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_trees.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_trees)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Best Number of Trees to Use: 8\n",
      "R^2 Value: 0.314316467022\n"
     ]
    }
   ],
   "source": [
    "# get best number of trees\n",
    "index, value = max(enumerate(r2_test_rf_trees), key=operator.itemgetter(1))\n",
    "best_trees2 = trees[index]\n",
    "print('RandomForest Best Number of Trees to Use:',best_trees2)\n",
    "print('R^2 Value:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Values for Train Using Random Forest Regression: [0.70232486693060547, 0.75232293394050664, 0.82584846666606015, 0.78871358857309493, 0.83202340852814349, 0.77036950971865881, 0.69750841053357981, 0.72221566935792425, 0.82605330010820466, 0.88908987028320463, 0.53399337078805409, 0.79383875094158807, 0.74279856771067865, 0.85108796833255596, 0.74823493502486782, 0.82653720416043419, 0.7730303767973743, 0.84385479353062809, 0.88503861073119205, 0.80246760369575221, 0.85823249778833055, 0.82757283843921481, 0.75650047731025472, 0.82466286040349956, 0.82286799297186164, 0.90786430348903646, 0.80296110444585667, 0.7732600660515343, 0.86276618975212127, 0.86030642846261174, 0.80603377507793905, 0.79419412234228093, 0.8796156487774599, 0.86094027884788926, 0.82723584845490716, 0.86540695672811618, 0.75646342389032162, 0.78299155506435558, 0.86664667606014179, 0.88392426278384006, 0.85124097497081319, 0.89521892610276799]\n",
      "\n",
      "\n",
      "R^2 Values for Test Using Random Forest Regression: [0.092717344643209132, 0.094593667752054245, 0.089045371693652786, 0.16665762736042777, 0.15111036451681359, 0.17510254998627084, 0.20746893289082557, 0.22857246753596672, 0.16530607989213286, 0.19620701973239218, 0.20768854825483851, 0.20150349832306269, 0.17172688020391635, 0.16702186823260856, 0.19036011512758244, 0.21385639551253277, 0.31334569036887849, 0.22052555198492041, 0.25299488737851838, 0.15720987163200195, 0.16647038575184647, 0.20757375354473684, 0.27097265316292385, 0.17030254694346936, 0.25645017817448812, 0.23796989681030944, 0.16319415959747441, 0.18771837208612918, 0.26067904336393111, 0.23929073388530175, 0.29609618935945525, 0.20807950624409377, 0.25324564981088693, 0.27617087640579607, 0.23520605402802142, 0.18900045383276276, 0.25093097931144603, 0.28351929555412581, 0.17589986631349519, 0.15661253725044777, 0.19825301051734567, 0.25918879113528936]\n"
     ]
    }
   ],
   "source": [
    "# step 2: fine tuning number of predictors used\n",
    "r2_train_rf_feat = []\n",
    "r2_test_rf_feat = []\n",
    "for i in range(1, 43):\n",
    "    rf = RandomForestRegressor(n_estimators=best_trees2, max_depth=best_depth2, max_features=i)\n",
    "    rf.fit(X_train, y_train)\n",
    "\n",
    "    rf_yhat_train = rf.predict(X_train)\n",
    "    rf_yhat_test = rf.predict(X_test)\n",
    "\n",
    "    r2_train_rf_feat.append(r2_score(y_train, rf_yhat_train))\n",
    "    r2_test_rf_feat.append(r2_score(y_test, rf_yhat_test))\n",
    "    \n",
    "print('R^2 Values for Train Using Random Forest Regression:', r2_train_rf_feat)\n",
    "print('\\n')\n",
    "print('R^2 Values for Test Using Random Forest Regression:', r2_test_rf_feat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForest Number of Predictors for Best value: 17\n",
      "Final Best R^2 Value: 0.313345690369\n"
     ]
    }
   ],
   "source": [
    "# get best number of predictors and best R^2 value\n",
    "index, value = max(enumerate(r2_test_rf_feat), key=operator.itemgetter(1))\n",
    "print('RandomForest Number of Predictors for Best value:',index+1)\n",
    "print('Final Best R^2 Value:',value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
